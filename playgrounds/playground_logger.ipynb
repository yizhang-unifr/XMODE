{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "from langgraph.prebuilt import ToolInvocation\n",
                "import json\n",
                "from langchain_core.messages import FunctionMessage, BaseMessage\n",
                "from typing import TypedDict, Annotated, Sequence\n",
                "import operator\n",
                "from langgraph.graph import StateGraph, END\n",
                "from langchain_core.messages import BaseMessage\n",
                "from tools.logger import JsonFormatter\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "\n",
                "def add_timestamp_to_file(file_path):\n",
                "    fp = Path(file_path)\n",
                "    if not fp.exists():\n",
                "        fp.touch()\n",
                "        abs_fp = Path(file_path).resolve().absolute()\n",
                "        abs_fp = abs_fp.with_stem(abs_fp.stem + '_' + datetime.now().strftime('%Y-%m-%d-%H%M%S.%f'))\n",
                "    return abs_fp\n",
                "\n",
                "def configure_logger(state, log_name=None, log_filename=None):\n",
                "    configurable = state['configurable']\n",
                "    # check logger is already configured\n",
                "    if configurable.get('logger') is None:\n",
                "        # set up logger\n",
                "        if log_name is None:\n",
                "            log_name = 'default_logger'\n",
                "        if log_filename is None:\n",
                "            log_filename = 'default_log.log'\n",
                "        configurable['logger'] = {\n",
                "            'log_filename': log_filename,\n",
                "            'log_name': log_name \n",
                "        }\n",
                "    log_name = configurable['logger']['log_name']\n",
                "    log_filename = configurable['logger']['log_filename']\n",
                "    logger = logging.getLogger(log_name)\n",
                "    logger.setLevel(logging.INFO)\n",
                "    # Create file handler which logs even debug messages\n",
                "    fh = logging.FileHandler(log_filename)\n",
                "    fh.setLevel(logging.INFO)\n",
                "    # Create formatter and add it to the handlers\n",
                "    formatter = JsonFormatter({\"level\": \"levelname\", \n",
                "                                    \"message\": \"message\", \n",
                "                                    \"timestamp\": \"asctime\"})\n",
                "    # formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
                "    fh.setFormatter(formatter)\n",
                "    # Add the handlers to logger\n",
                "    if not logger.hasHandlers():\n",
                "        logger.addHandler(fh)\n",
                "    return logger\n",
                "\n",
                "def delete_logger(state):\n",
                "    configurable = state['configurable']\n",
                "    if configurable.get('logger') is not None:\n",
                "        log_name = configurable['logger']['log_name']\n",
                "        logger = logging.getLogger(log_name)\n",
                "        # remove all handlers\n",
                "        for handler in logger.handlers[:]:\n",
                "            logger.removeHandler(handler)\n",
                "        # remove logger from state\n",
                "        del logger\n",
                "        state['configurable'].pop('logger', None)\n",
                "\n",
                "# Define the function that determines whether to continue or not\n",
                "def should_continue(state):\n",
                "    logger = configure_logger(state)\n",
                "    messages = state['messages']\n",
                "    last_message = messages[-1]\n",
                "    logger.info(\"Deciding whether to continue based on the last message: %s\", last_message)\n",
                "    # If there is no function call then we finish\n",
                "    if \"function_call\" not in last_message.additional_kwargs:\n",
                "        logger.info(\"should_continue: end\")\n",
                "        # remove logger from state\n",
                "        delete_logger(state)\n",
                "        return \"end\"\n",
                "    # Otherwise if there is we continue\n",
                "    else:\n",
                "        logger.info(\"should_continue: continue\")\n",
                "        return \"continue\"\n",
                "\n",
                "# Define the function that calls the model\n",
                "def call_model(state):\n",
                "    logger = configure_logger(state)\n",
                "    messages = state['messages']\n",
                "    logger.info(\"Calling model with messages: %s\", messages)\n",
                "    response = model.invoke(messages)\n",
                "    logger.info(\"Model response: %s\", response)\n",
                "    # We return a list because this will get added to the existing list\n",
                "    return {\"messages\": [response]}\n",
                "\n",
                "# Define the function to execute tools\n",
                "def call_tool(state):\n",
                "    logger = configure_logger(state)\n",
                "    messages = state['messages']\n",
                "    last_message = messages[-1]\n",
                "    logger.info(\"Calling tool with last message: %s\", last_message)\n",
                "    action = ToolInvocation(\n",
                "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
                "        tool_input=json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"])\n",
                "    )\n",
                "    response = tool_executor.invoke(action)\n",
                "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
                "    logger.info(\"Tool response: %s\", function_message)\n",
                "    # We return a list because this will get added to the existing list\n",
                "    return {\"messages\": [function_message]}\n",
                "\n",
                "class AgentState(TypedDict):\n",
                "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
                "    configurable: TypedDict  # Add configurable attribute for log filename\n",
                "\n",
                "# Define a new graph\n",
                "workflow = StateGraph(AgentState)\n",
                "\n",
                "# Define the two nodes we will cycle between\n",
                "workflow.add_node(\"agent\", call_model)\n",
                "workflow.add_node(\"action\", call_tool)\n",
                "\n",
                "# Set the entrypoint as `agent`\n",
                "workflow.set_entry_point(\"agent\")\n",
                "\n",
                "# Add conditional edges\n",
                "workflow.add_conditional_edges(\n",
                "    \"agent\",\n",
                "    should_continue,\n",
                "    {\n",
                "        \"continue\": \"action\",\n",
                "        \"end\": END\n",
                "    }\n",
                ")\n",
                "\n",
                "# Add a normal edge from `action` to `agent`\n",
                "workflow.add_edge('action', 'agent')\n",
                "\n",
                "# Compile the graph\n",
                "app = workflow.compile()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community. chat_models.fake import FakeMessagesListChatModel\n",
                "from langchain_core.messages import HumanMessage, AIMessage\n",
                "\n",
                "\n",
                "# Define a list of responses that the fake model will use\n",
                "responses = [\n",
                "    AIMessage(content=\"The weather in San Francisco is sunny.\"),\n",
                "    AIMessage(content=\"I'm sorry, I couldn't fetch the weather details.\")\n",
                "]\n",
                "\n",
                "model = FakeMessagesListChatModel(responses=responses)\n",
                "\n",
                "# Set up the tool executor (assuming you have defined your tools)\n",
                "from langgraph.prebuilt import ToolExecutor\n",
                "tools = []  # Define your tools here\n",
                "tool_executor = ToolExecutor(tools)\n",
                "\n",
                "# Example state with configurable log file name\n",
                "state = {\n",
                "    \"messages\": [HumanMessage(content=\"what is the weather in sf\")],\n",
                "    \"configurable\": {}\n",
                "}\n",
                "\n",
                "logger = configure_logger(state, 'my_logger', 'my_log.log')\n",
                "logger.info(\"Initial input: %s\", state)\n",
                "\n",
                "output = app.invoke(state)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "PosixPath('/home/ubuntu/workspace/XMODE-LLMCompiler/my_log_2024-07-19-115546.479404.log')"
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "abs_fp = add_timestamp_to_file('my_log.log')\n",
                "# add current datetime in yyyy-mm-dd-hMS.ms to the abs_fp stem\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "xmode",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}