{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2 \n",
                "\n",
                "## Sample the 100 data with the less images required\n",
                "\n",
                "For keep the consistency of the data, we will sample the 70 data with the less images required and concatenate with the 30 data filtered in the first part."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "root = Path('.').cwd().parent\n",
                "dataset_path = root / 'dataset' / 'mimic_iv_cxr'\n",
                "filtered_path = dataset_path / 'filtered_test_with_scope_preprocessed.json'\n",
                "with open(filtered_path, 'r') as f:\n",
                "    filtered_test_data = json.load(f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "2295"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(filtered_test_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### We need to sample 100 data points and add them to the 30 data points we already have. \n",
                "\n",
                "#### Steps:\n",
                "1. Remove the 30 data points from the filtered dataset\n",
                "2. Sample 70 data points from the filtered dataset after removing the 30 data points\n",
                "3. group the data by the category and re-sort the data points by the number of images\n",
                "4. re-concatenate the grouped data "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check the ids from the 30 samples\n",
                "sampled_test_30 = dataset_path / 'sampled_test_with_scope_preprocessed_balenced_answer.json'\n",
                "with open(sampled_test_30, 'r') as f:\n",
                "    sampled_test_30_data = json.load(f)\n",
                "\n",
                "sampled_test_30_data_ids = [d['id'] for d in sampled_test_30_data]\n",
                "\n",
                "# remove the ids from the filtered_test_data if they are in the sampled_test_30_data\n",
                "left_filtered_test_data = [d for d in filtered_test_data if d['id'] not in sampled_test_30_data_ids]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2265 2295\n"
                    ]
                }
            ],
            "source": [
                "print(len(left_filtered_test_data), len(filtered_test_data))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "IMAGE-SINGLE-1 395 89\n",
                        "IMAGE-SINGLE-1 0 20\n",
                        "IMAGE-SINGLE-2 225 119\n",
                        "IMAGE-SINGLE-2 0 20\n",
                        "MULTIMODAL-SINGLE 977 0\n",
                        "MULTIMODAL-SINGLE 30 0\n"
                    ]
                }
            ],
            "source": [
                "# get first 10 samples from each category in filtered dataset\n",
                "res = []\n",
                "max_sapmles_all_categories = [20,20,30]\n",
                "max_samples_all_answertype = [int(m) for m in max_sapmles_all_categories]\n",
                "categories = [\"IMAGE-SINGLE-1\", \"IMAGE-SINGLE-2\", \"MULTIMODAL-SINGLE\"]\n",
                "for scope, max_sapmles_per_category, max_samples_per_answertype in zip(categories, max_sapmles_all_categories, max_samples_all_answertype):\n",
                "    data_per_scope = []\n",
                "    for d in left_filtered_test_data:\n",
                "        if d['scope'] == scope and len(d['answer']) > 0:\n",
                "            data_per_scope.append(d)\n",
                "    data_per_scope = sorted(data_per_scope, key=lambda x: x['num_required_images'])\n",
                "    data_per_scope_single_numeric_value = list(filter(lambda x: len(x['answer']) == 1 and isinstance(x['answer'][0], int), data_per_scope))\n",
                "    data_per_scope_list_value = list(filter(lambda x: len(x['answer']) > 1, data_per_scope))\n",
                "    num_single_value = len(data_per_scope_single_numeric_value)\n",
                "    num_list_value = len(data_per_scope_list_value)\n",
                "    print(scope, num_single_value, num_list_value)\n",
                "    # we want to have more list value than single value\n",
                "    num_single_value = 0\n",
                "    num_list_value = min(max_sapmles_per_category - num_single_value, num_list_value)\n",
                "    if num_list_value < max_samples_per_answertype:\n",
                "        num_single_value = max(max_sapmles_per_category - num_list_value, num_single_value)\n",
                "        num_list_value = max_sapmles_per_category - num_single_value\n",
                "    else:\n",
                "        assert num_list_value == max_samples_per_answertype\n",
                "    print(scope, num_single_value, num_list_value)\n",
                "    res.extend(data_per_scope_single_numeric_value[:num_single_value])\n",
                "    res.extend(data_per_scope_list_value[:num_list_value])\n",
                "\n",
                "res = res + sampled_test_30_data\n",
                "\n",
                "# group res by eachj category and sort it by num_required_images\n",
                "res = sorted(res, key=lambda x: x['num_required_images'])\n",
                "res_grouped = {}\n",
                "for scope in categories:\n",
                "    res_grouped[scope] = [d for d in res if d['scope'] == scope]\n",
                "\n",
                "# re-concate the res_grouped\n",
                "res = []\n",
                "for scope in categories:\n",
                "    res.extend(res_grouped[scope])\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[30, 30, 40]\n"
                    ]
                }
            ],
            "source": [
                "# group res by eachj category and sort it by id\n",
                "res = sorted(res, key=lambda x: x['id'])\n",
                "res_grouped = {}\n",
                "for scope in categories:\n",
                "    res_grouped[scope] = [d for d in res if d['scope'] == scope]\n",
                "\n",
                "print([len(res_grouped[scope]) for scope in categories])\n",
                "# re-concate the res_grouped\n",
                "res = []\n",
                "for scope in categories:\n",
                "    res.extend(res_grouped[scope])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "sampled_test = dataset_path / 'sampled_test_with_scope_preprocessed_balenced_answer_100.json'\n",
                "with open(sampled_test, 'w') as f:\n",
                "    json.dump(res, f, indent=4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "root = Path('.').cwd().parent\n",
                "dataset_path = root / 'dataset' / 'mimic_iv_cxr'\n",
                "sampled_test_100 = dataset_path / 'sampled_test_with_scope_preprocessed_balenced_answer_100.json'\n",
                "sampled_test_30 = dataset_path / 'sampled_test_with_scope_preprocessed_balenced_answer.json'\n",
                "sampled_test_70 = dataset_path / 'sampled_test_with_scope_preprocessed_balenced_answer_70.json'\n",
                "with open(sampled_test_100, 'r') as f:\n",
                "    sampled_test_100_data = json.load(f)\n",
                "with open(sampled_test_30, 'r') as f:\n",
                "    sampled_test_30_data = json.load(f)\n",
                "\n",
                "idx_30 = [d['id'] for d in sampled_test_30_data]\n",
                "idx_100 = [d['id'] for d in sampled_test_100_data]\n",
                "idx_70 = [d['id'] for d in sampled_test_100_data if d['id'] not in idx_30]\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_test_70_data = [d for d in sampled_test_100_data if d['id'] in idx_70]\n",
                "with open(sampled_test_70, 'w') as f:\n",
                "    json.dump(sample_test_70_data, f, indent=4)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "xmode",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}