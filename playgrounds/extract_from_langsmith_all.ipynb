{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langsmith import Client\n",
                "import os\n",
                "client = Client()\n",
                "project_name=\"\"\n",
                "def _set_if_undefined(var: str):\n",
                "    if not os.environ.get(var):\n",
                "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
                "_set_if_undefined(\"OPENAI_API_KEY\")\n",
                "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
                "_set_if_undefined(\"LANGCHAIN_API_YI_KEY\")\n",
                "os.environ[\"LANGCHAIN_API_KEY\"] = os.environ[\"LANGCHAIN_API_YI_KEY\"]\n",
                "\n",
                "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
                "os.environ[\"LANGCHAIN_PROJECT\"] = \"xmode-vqa-gpt_4o-english-100-with-intent\"\n",
                "project_name=os.environ[\"LANGCHAIN_PROJECT\"]\n",
                "project_runs = list(client.list_runs(project_name=project_name, is_root=True))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter out only successful runs\n",
                "success_project_runs = [run for run in project_runs if run.status == \"success\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "100"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(success_project_runs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "dict_keys(['id', 'name', 'start_time', 'run_type', 'end_time', 'extra', 'error', 'serialized', 'events', 'inputs', 'outputs', 'reference_example_id', 'parent_run_id', 'tags', 'session_id', 'child_run_ids', 'child_runs', 'feedback_stats', 'app_path', 'manifest_id', 'status', 'prompt_tokens', 'completion_tokens', 'total_tokens', 'first_token_time', 'total_cost', 'prompt_cost', 'completion_cost', 'parent_run_ids', 'trace_id', 'dotted_order', 'in_dataset'])"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "success_project_runs[0].__dict__.keys()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "from decimal import Decimal\n",
                "from uuid import UUID\n",
                "from datetime import datetime\n",
                "from tqdm import tqdm as tqdm\n",
                "from time import sleep\n",
                "\n",
                "def handle_value(value):\n",
                "    if isinstance(value, UUID):\n",
                "        return str(value)\n",
                "    if isinstance(value, Decimal):\n",
                "        return float(value)\n",
                "    if isinstance(value, datetime):\n",
                "        return value.isoformat()\n",
                "    if isinstance(value, dict):\n",
                "        return {key: handle_value(val) for key, val in value.items()}\n",
                "    if isinstance(value, list):\n",
                "        return [handle_value(val) for val in value]\n",
                "    return value\n",
                "\n",
                "\n",
                "\n",
                "def _extract_run(run):\n",
                "    keys = run.__dict__.keys()\n",
                "    temp =  {key: handle_value(run.__dict__[key]) for key in keys}\n",
                "    p_id = temp[\"id\"]\n",
                "    if isinstance(temp.get('child_run_ids', None), list) and len(temp['child_run_ids']) > 0:\n",
                "        # print(\"****\", temp['child_run_ids'])\n",
                "        c_runs = []\n",
                "        max_retry = 3\n",
                "        retry = 0\n",
                "        try:\n",
                "            c_runs = list(client.list_runs(project_name=project_name, parent_run_id=p_id))\n",
                "            sleep(1)\n",
                "        except:\n",
                "            while len(c_runs) == 0 and retry < max_retry:\n",
                "                retry += 1\n",
                "                try:\n",
                "                    c_runs = list(client.list_runs(project_name=project_name, parent_run_id=p_id))\n",
                "                    sleep(10)\n",
                "                except:\n",
                "                    print(\"retrying...\")\n",
                "                \n",
                "        # print(\"add child:\", [r.id for r in c_runs])\n",
                "        res = {\n",
                "            **temp,\n",
                "            'child_runs': [_extract_run(_run) for _run in c_runs]\n",
                "        }\n",
                "        if not any(res['child_runs']):\n",
                "            res['child_runs'] = None\n",
                "        return res\n",
                "    if temp.get('type','ChatGenerationChunk') == 'ChatGenerationChunk':\n",
                "        return\n",
                "    return temp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 100/100 [2:18:18<00:00, 82.98s/it]  \n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "from time import sleep\n",
                "from tqdm import tqdm as tqdm\n",
                "for run in tqdm(success_project_runs[::-1], total=len(success_project_runs)):\n",
                "    run = _extract_run(run)\n",
                "    with open(\"experiments/xmode/en/xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent-langsmith-extract_all.json\", \"r+\") as f:\n",
                "        # load existing data\n",
                "        try:\n",
                "            data = json.load(f)\n",
                "        except json.JSONDecodeError:\n",
                "            data = []\n",
                "        # update data\n",
                "        data.append(run)\n",
                "        # save data\n",
                "        f.seek(0)\n",
                "        json.dump(data, f, indent=2)\n",
                "        f.truncate()\n",
                "    sleep(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "res = []\n",
                "for run in success_project_runs:\n",
                "    res.append(_extract_run(run))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "with open(\"experiments/xmode/en/metadata_xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent.json\", \"w\") as f:\n",
                "    json.dump(res[::-1], f, indent=2) # reverse the order to match the order of the questions in the dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(\"experiments/xmode/en/metadata_xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent.json\", \"r\") as f:\n",
                "    res = json.load(f)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = \"/home/ubuntu/workspace/XMODE-LLMCompiler/experiments/xmode/en/xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent.json\"\n",
                "with open(data_path, \"r\") as f:\n",
                "    data = json.load(f)\n",
                "\n",
                "for d,r in zip(data,res):\n",
                "    assert d[\"question\"]==r[\"question\"], print(d[\"question\"],r[\"question\"])\n",
                "    d[\"prompt_tokens\"] = r[\"prompt_tokens\"]\n",
                "    d[\"completion_tokens\"] = r[\"completion_tokens\"]\n",
                "    d[\"total_tokens\"] = r[\"total_tokens\"]\n",
                "    d[\"prompt_cost\"] = r[\"prompt_cost\"]\n",
                "    d[\"completion_cost\"] = r[\"completion_cost\"]\n",
                "    d[\"total_cost\"] = r[\"total_cost\"]\n",
                "\n",
                "merged_data_path = \"/home/ubuntu/workspace/XMODE-LLMCompiler/experiments/xmode/en/xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent-with-meta.json\"\n",
                "with open(merged_data_path, \"w\") as f:\n",
                "    json.dump(data, f, indent=2)\n",
                "\n",
                "import pandas as pd\n",
                "df = pd.DataFrame(data)\n",
                "df.to_csv(\"/home/ubuntu/workspace/XMODE-LLMCompiler/experiments/xmode/en/xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent-with-meta.csv\", index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.to_excel(\"/home/ubuntu/workspace/XMODE-LLMCompiler/experiments/xmode/en/xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent-with-meta.xlsx\", index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "\"given the last study of patient 10284038 in 2105, is the cardiac silhouette's width larger than half of the total thorax width?\""
                        ]
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "xmode",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}