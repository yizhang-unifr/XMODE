{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langsmith import Client\n",
                "import os\n",
                "from langsmith_utils import extract_and_save_all_child_runs_by_project\n",
                "client = Client()\n",
                "\n",
                "def _set_if_undefined(var: str):\n",
                "    if not os.environ.get(var):\n",
                "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
                "_set_if_undefined(\"OPENAI_API_KEY\")\n",
                "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
                "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langsmith_utils import extract_plan_and_details\n",
                "from pathlib import Path\n",
                "import json\n",
                "from tqdm import tqdm\n",
                "def save_reduced_details(project_name, data_path=\"experiments/xmode/en\"):\n",
                "    test_run_folder = f\"{project_name}-details\"\n",
                "    data_path = Path(data_path)\n",
                "    test_run_folder = data_path / test_run_folder\n",
                "    # get all json files under the test_run_folder\n",
                "    assert test_run_folder.exists(), f\"{test_run_folder} does not exist\"\n",
                "    test_run_files = list(test_run_folder.glob(\"*.json\"))\n",
                "    reduced_run_folder = data_path / f\"{project_name}-details-reduced\"\n",
                "    Path(reduced_run_folder).mkdir(parents=True, exist_ok=True)\n",
                "    all_plans = []\n",
                "    for test_run_file in tqdm(test_run_files):\n",
                "        # get the stem of the file\n",
                "        try:\n",
                "            i = int(test_run_file.stem)\n",
                "            with open(test_run_file, \"r\") as f:\n",
                "                data = json.load(f)\n",
                "            _result = extract_plan_and_details(data)\n",
                "            reduced_run_path = Path(reduced_run_folder) / f\"{i}.json\"\n",
                "            with open(reduced_run_path, \"w\") as f:\n",
                "                json.dump(_result, f, indent=2)\n",
                "            all_plans.append(_result)\n",
                "        except ValueError:\n",
                "            print(f\"Skipping {test_run_file.stem}.{test_run_file.suffix}\")\n",
                "            continue\n",
                "    output_path = Path(reduced_run_folder).parent / f\"{project_name}-details-reduced.json\"\n",
                "    with open(output_path, \"w\") as f:\n",
                "        json.dump(all_plans, f, indent=2)\n",
                "    print(f\"Saved to {output_path}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.environ[\"LANGCHAIN_PROJECT\"] = \"xmode-vqa-gpt_4o-english-13\"\n",
                "project_name=os.environ[\"LANGCHAIN_PROJECT\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/13 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13/13 [00:00<00:00, 40.22it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved to experiments/xmode/en/xmode-vqa-gpt_4o-english-13-details-reduced.json\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "# extract_and_save_all_child_runs_by_project(project_name)\n",
                "save_reduced_details(project_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 52/52 [00:01<00:00, 42.37it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved to experiments/xmode/en/xmode-vqa-gpt_4o-english-52-details-reduced.json\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "os.environ[\"LANGCHAIN_PROJECT\"] = \"xmode-vqa-gpt_4o-english-52\"\n",
                "project_name=os.environ[\"LANGCHAIN_PROJECT\"]\n",
                "# extract_and_save_all_child_runs_by_project(project_name)\n",
                "save_reduced_details(project_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# merge the data to the exsisted file.\n",
                "import pandas as pd\n",
                "import json\n",
                "from pathlib import Path\n",
                "data_path = Path(\"experiments/xmode/en\")\n",
                "json_file_1 = data_path / \"xmode-vqa-gpt_4o-english-13-details-reduced.json\"\n",
                "json_file_2 = data_path / \"xmode-vqa-gpt_4o-english-52-details-reduced.json\"\n",
                "with open(json_file_1, \"r\") as f:\n",
                "    data_1 = json.load(f)\n",
                "with open(json_file_2, \"r\") as f:\n",
                "    data_2 = json.load(f)\n",
                "data = data_1 + data_2\n",
                "source_xlxs = \"eval_ehr_100_samples.xlsx\"\n",
                "df = pd.read_excel(source_xlxs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'was patient 12724975 diagnosed with hypoxemia until 1 year ago and did a chest x-ray reveal any tubes/lines in the abdomen during the same period?'"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.iloc[60][\"question\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'was patient 12724975 diagnosed with hypoxemia until 1 year ago and did a chest x-ray reveal any tubes/lines in the abdomen during the same period?'"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data[0][\"question\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "\"[{'Summary': 'Patient 12724975 was diagnosed with hypoxemia until about two years ago and no tubes/lines were detected in the abdomen during chest x-rays in the last year.', 'details': 'The patient had a diagnosis of hypoxemia recorded on 2103-12-27. Chest x-ray analysis from the last year (2104-12-31 to 2105-12-31) revealed no tubes or lines in the abdomen.', 'source': 'Diagnosis records and chest x-ray image analysis.', 'inference': 'no', 'extra explanation': 'The diagnosis occurred two years ago, not within the last year. No tubes or lines were observed in the x-rays.'}]\""
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.iloc[60][\"prediction\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['Plans (updated with SQL)', 'prediction', 'question'], dtype='object')"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "json_df = pd.DataFrame(data)\n",
                "# rename the columns\n",
                "json_df = json_df.rename(columns={\"plans\": \"Plans (updated with SQL)\", \"predictions\": \"prediction\"})\n",
                "json_df.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "for index, row in json_df.iterrows():\n",
                "    question = row[\"question\"]\n",
                "\n",
                "    df.loc[df['question'] == question, 'Plans (updated with SQL)'] = str(row['Plans (updated with SQL)'])\n",
                "    df.loc[df['question'] == question, 'prediction'] = str(row['prediction'])\n",
                "\n",
                "df.to_excel(\"eval_ehr_100_samples_updated.xlsx\", index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# for the json data we need to add an question_id from the df\n",
                "json_df[\"id\"] = 0\n",
                "for index, row in json_df.iterrows():\n",
                "    question = row[\"question\"]\n",
                "    question_id = df[df[\"question\"] == question][\"id\"].values[0]\n",
                "    json_df.loc[index, \"id\"] = question_id\n",
                "# change the type of json_df[\"id\"] to int\n",
                "json_df[\"id\"] = json_df[\"id\"].astype(int)\n",
                "\n",
                "# convert the json_df to a list of dictionaries\n",
                "json_data = json_df.to_dict(orient=\"records\")\n",
                "\n",
                "# save the json_data to json files under the data_path\n",
                "data_path = Path(\"experiments/xmode/en\")\n",
                "json_folder = data_path / \"xmode-vqa-gpt_4o-english-13-details-reduced-tagged\"\n",
                "Path(json_folder).mkdir(parents=True, exist_ok=True)\n",
                "for d in json_data:\n",
                "    i = d[\"id\"]\n",
                "    with open(Path(json_folder) / f\"{i}.json\", \"w\") as f:\n",
                "        json.dump(d, f, indent=2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "execution_count": 55,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "json_data[0][\"question_id\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/100 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 100/100 [00:00<00:00, 269.33it/s]\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "import json\n",
                "from tqdm import tqdm\n",
                "import pandas as pd\n",
                "\n",
                "data_path = Path(\"dataset/mimic_iv_cxr/sampled_test_with_scope_preprocessed_balenced_answer_100.json\")\n",
                "eval_folder = Path(\"experiments/xmode/en/xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent-langsmith-extract-details-reduced\")\n",
                "# get all json files under the eval_folder\n",
                "assert eval_folder.exists(), f\"{eval_folder} does not exist\"\n",
                "eval_files = list(eval_folder.glob(\"*.json\"))\n",
                "output_folder = Path(\"experiments/xmode/en/xmode-vqa-m3ae-star-100-en-gpt_4o-with-intent-langsmith-extract-details-reduced-tagged\")\n",
                "output_folder.mkdir(parents=True, exist_ok=True)\n",
                "# load the data\n",
                "with open(data_path, \"r\") as f:\n",
                "    data = json.load(f)\n",
                "    df = pd.DataFrame(data)\n",
                "# iterate over the eval_files\n",
                "\n",
                "for eval_file in tqdm(eval_files):\n",
                "    with open(eval_file, \"r\") as f:\n",
                "        eval_data = json.load(f)\n",
                "    # get the question_id from the df by same question\n",
                "    question = eval_data[\"question\"]\n",
                "    question_id = df[df[\"question\"] == question][\"id\"].values[0]\n",
                "    # output the question_id to the eval_data\n",
                "    eval_data[\"id\"] = int(question_id)\n",
                "    # save the eval_data to the output_folder\n",
                "    output_file = output_folder / f\"{question_id}.json\"\n",
                "    with open(output_file, \"w\") as f:\n",
                "        json.dump(eval_data, f, indent=2)\n",
                "\n",
                "    "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "m3lx",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
